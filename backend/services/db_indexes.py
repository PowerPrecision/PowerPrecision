"""
====================================================================
√çNDICES DE BASE DE DADOS - OPTIMIZA√á√ÉO DE PERFORMANCE
====================================================================
Script para criar √≠ndices nas colec√ß√µes MongoDB mais consultadas.
Melhora significativamente o tempo de resposta para queries frequentes.

Executar manualmente ou na inicializa√ß√£o da aplica√ß√£o.
====================================================================
"""
import logging
from motor.motor_asyncio import AsyncIOMotorDatabase

logger = logging.getLogger(__name__)


# Lista de √≠ndices antigos/incorretos que devem ser removidos
DEPRECATED_INDEXES = {
    "properties": [
        "idx_internal_ref",  # Nome antigo incorreto - campo era internal_ref
    ]
}


async def cleanup_deprecated_indexes(db) -> dict:
    """
    Remove √≠ndices antigos/incorretos que podem causar erros.
    Executa antes de criar novos √≠ndices.
    """
    results = {"dropped": [], "errors": [], "not_found": []}
    
    for collection_name, index_names in DEPRECATED_INDEXES.items():
        collection = getattr(db, collection_name)
        
        try:
            # Obter √≠ndices existentes
            existing_indexes = await collection.index_information()
            
            for idx_name in index_names:
                if idx_name in existing_indexes:
                    try:
                        await collection.drop_index(idx_name)
                        results["dropped"].append(f"{collection_name}.{idx_name}")
                        logger.info(f"üóëÔ∏è √çndice removido: {collection_name}.{idx_name}")
                    except Exception as e:
                        results["errors"].append(f"{collection_name}.{idx_name}: {str(e)}")
                        logger.error(f"Erro ao remover √≠ndice {collection_name}.{idx_name}: {e}")
                else:
                    results["not_found"].append(f"{collection_name}.{idx_name}")
        except Exception as e:
            results["errors"].append(f"{collection_name}: {str(e)}")
            logger.error(f"Erro ao verificar √≠ndices em {collection_name}: {e}")
    
    if results["dropped"]:
        logger.info(f"‚úÖ Limpeza de √≠ndices conclu√≠da: {len(results['dropped'])} removidos")
    
    return results


async def create_indexes(db) -> dict:
    """
    Cria √≠ndices optimizados nas colec√ß√µes principais.
    
    Returns:
        dict: Resumo dos √≠ndices criados
    """
    # Primeiro, limpar √≠ndices antigos/incorretos
    cleanup_results = await cleanup_deprecated_indexes(db)
    
    results = {
        "created": [],
        "errors": [],
        "skipped": [],
        "cleanup": cleanup_results
    }
    
    # ====================================================================
    # √çNDICES PARA COLEC√á√ÉO 'processes'
    # ====================================================================
    process_indexes = [
        # √çndice no status - muito usado em filtros e dashboard
        {"keys": [("status", 1)], "name": "idx_status"},
        
        # √çndice no nome do cliente - usado em pesquisa
        {"keys": [("client_name", 1)], "name": "idx_client_name"},
        
        # √çndice no email do cliente - usado em lookup
        {"keys": [("client_email", 1)], "name": "idx_client_email"},
        
        # √çndice na data de cria√ß√£o - usado para ordena√ß√£o
        {"keys": [("created_at", -1)], "name": "idx_created_at_desc"},
        
        # √çndice no consultor atribu√≠do - usado em filtros por utilizador
        {"keys": [("assigned_consultor_id", 1)], "name": "idx_consultor"},
        
        # √çndice no mediador atribu√≠do
        {"keys": [("assigned_mediador_id", 1)], "name": "idx_mediador"},
        
        # √çndice composto status + created_at - muito usado em listagens
        {"keys": [("status", 1), ("created_at", -1)], "name": "idx_status_created"},
        
        # √çndice no NIF para pesquisa r√°pida
        {"keys": [("personal_data.nif", 1)], "name": "idx_nif", "sparse": True},
        
        # √çndice no tipo de processo
        {"keys": [("process_type", 1)], "name": "idx_process_type"},
        
        # √çndice de texto para pesquisa full-text
        {
            "keys": [
                ("client_name", "text"), 
                ("client_email", "text"),
                ("personal_data.nif", "text")
            ], 
            "name": "idx_text_search"
        },
    ]
    
    for idx in process_indexes:
        try:
            await db.processes.create_index(
                idx["keys"],
                name=idx["name"],
                sparse=idx.get("sparse", False),
                background=True  # N√£o bloqueia opera√ß√µes durante cria√ß√£o
            )
            results["created"].append(f"processes.{idx['name']}")
            logger.info(f"√çndice criado: processes.{idx['name']}")
        except Exception as e:
            if "already exists" in str(e).lower():
                results["skipped"].append(f"processes.{idx['name']}")
            else:
                results["errors"].append(f"processes.{idx['name']}: {str(e)}")
                logger.error(f"Erro ao criar √≠ndice processes.{idx['name']}: {e}")
    
    # ====================================================================
    # √çNDICES PARA COLEC√á√ÉO 'users'
    # ====================================================================
    user_indexes = [
        # √çndice √∫nico no email - login
        {"keys": [("email", 1)], "name": "idx_email", "unique": True},
        
        # √çndice no ID do utilizador
        {"keys": [("id", 1)], "name": "idx_user_id", "unique": True},
        
        # √çndice no role - filtros por tipo de utilizador
        {"keys": [("role", 1)], "name": "idx_role"},
        
        # √çndice composto role + is_active
        {"keys": [("role", 1), ("is_active", 1)], "name": "idx_role_active"},
    ]
    
    for idx in user_indexes:
        try:
            await db.users.create_index(
                idx["keys"],
                name=idx["name"],
                unique=idx.get("unique", False),
                sparse=idx.get("sparse", False),
                background=True
            )
            results["created"].append(f"users.{idx['name']}")
            logger.info(f"√çndice criado: users.{idx['name']}")
        except Exception as e:
            if "already exists" in str(e).lower():
                results["skipped"].append(f"users.{idx['name']}")
            else:
                results["errors"].append(f"users.{idx['name']}: {str(e)}")
                logger.error(f"Erro ao criar √≠ndice users.{idx['name']}: {e}")
    
    # ====================================================================
    # √çNDICES PARA COLEC√á√ÉO 'system_error_logs'
    # ====================================================================
    log_indexes = [
        # √çndice no timestamp - queries por per√≠odo
        {"keys": [("timestamp", -1)], "name": "idx_timestamp_desc"},
        
        # √çndice na severidade - filtros
        {"keys": [("severity", 1)], "name": "idx_severity"},
        
        # √çndice no componente - filtros
        {"keys": [("component", 1)], "name": "idx_component"},
        
        # √çndice composto para queries frequentes
        {"keys": [("timestamp", -1), ("severity", 1)], "name": "idx_time_severity"},
        
        # TTL index - auto-delete logs ap√≥s 90 dias
        {"keys": [("timestamp", 1)], "name": "idx_ttl", "expireAfterSeconds": 7776000},
    ]
    
    for idx in log_indexes:
        try:
            create_options = {
                "name": idx["name"],
                "background": True
            }
            if "expireAfterSeconds" in idx:
                create_options["expireAfterSeconds"] = idx["expireAfterSeconds"]
            
            await db.system_error_logs.create_index(idx["keys"], **create_options)
            results["created"].append(f"system_error_logs.{idx['name']}")
            logger.info(f"√çndice criado: system_error_logs.{idx['name']}")
        except Exception as e:
            if "already exists" in str(e).lower():
                results["skipped"].append(f"system_error_logs.{idx['name']}")
            else:
                results["errors"].append(f"system_error_logs.{idx['name']}: {str(e)}")
                logger.error(f"Erro ao criar √≠ndice system_error_logs.{idx['name']}: {e}")
    
    # ====================================================================
    # √çNDICES PARA COLEC√á√ÉO 'properties' (Im√≥veis)
    # ====================================================================
    property_indexes = [
        {"keys": [("internal_reference", 1)], "name": "idx_internal_reference", "unique": True, "sparse": True},
        {"keys": [("status", 1)], "name": "idx_property_status"},
        {"keys": [("address.district", 1), ("address.municipality", 1)], "name": "idx_location"},
        {"keys": [("financials.asking_price", 1)], "name": "idx_asking_price"},
        {"keys": [("created_at", -1)], "name": "idx_created_desc"},
    ]
    
    for idx in property_indexes:
        try:
            await db.properties.create_index(
                idx["keys"],
                name=idx["name"],
                unique=idx.get("unique", False),
                sparse=idx.get("sparse", False),
                background=True
            )
            results["created"].append(f"properties.{idx['name']}")
            logger.info(f"√çndice criado: properties.{idx['name']}")
        except Exception as e:
            if "already exists" in str(e).lower():
                results["skipped"].append(f"properties.{idx['name']}")
            else:
                results["errors"].append(f"properties.{idx['name']}: {str(e)}")
                logger.error(f"Erro ao criar √≠ndice properties.{idx['name']}: {e}")
    
    # ====================================================================
    # √çNDICES PARA COLEC√á√ÉO 'tasks'
    # ====================================================================
    task_indexes = [
        {"keys": [("process_id", 1)], "name": "idx_process_id"},
        {"keys": [("assigned_to", 1)], "name": "idx_assigned_to"},
        {"keys": [("status", 1)], "name": "idx_task_status"},
        {"keys": [("due_date", 1)], "name": "idx_due_date"},
        {"keys": [("status", 1), ("due_date", 1)], "name": "idx_status_due"},
    ]
    
    for idx in task_indexes:
        try:
            await db.tasks.create_index(
                idx["keys"],
                name=idx["name"],
                background=True
            )
            results["created"].append(f"tasks.{idx['name']}")
            logger.info(f"√çndice criado: tasks.{idx['name']}")
        except Exception as e:
            if "already exists" in str(e).lower():
                results["skipped"].append(f"tasks.{idx['name']}")
            else:
                results["errors"].append(f"tasks.{idx['name']}: {str(e)}")
                logger.error(f"Erro ao criar √≠ndice tasks.{idx['name']}: {e}")
    
    # Resumo
    logger.info(
        f"Cria√ß√£o de √≠ndices conclu√≠da: "
        f"{len(results['created'])} criados, "
        f"{len(results['skipped'])} j√° existiam, "
        f"{len(results['errors'])} erros"
    )
    
    return results


async def get_index_stats(db) -> dict:
    """
    Obt√©m estat√≠sticas dos √≠ndices existentes.
    """
    stats = {}
    
    collections = ["processes", "users", "system_error_logs", "properties", "tasks"]
    
    for collection_name in collections:
        try:
            collection = getattr(db, collection_name)
            indexes = await collection.index_information()
            stats[collection_name] = {
                "count": len(indexes),
                "indexes": list(indexes.keys())
            }
        except Exception as e:
            stats[collection_name] = {"error": str(e)}
    
    return stats
